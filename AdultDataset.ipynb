{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from utils import ConfusionMatrix, Prf1a\n",
    "classifiers = [\n",
    "#     KNeighborsClassifier(3),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(n_jobs=4),\n",
    "    AdaBoostClassifier()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'adult/adult.csv'\n",
    "kf = KFold(n_splits=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(clf, X_train, Y_train, X_test, Y_test, num_class):\n",
    "    clf.fit(X_train, Y_train)\n",
    "    train_predictions = clf.predict(X_test)\n",
    "    if num_class==2:\n",
    "        sc = Prf1a()\n",
    "    else:\n",
    "        sc = ConfusionMatrix(num_class)\n",
    "    sc.add(torch.FloatTensor(train_predictions), Y_test)\n",
    "    train_predictions = clf.predict_proba(X_test)\n",
    "    return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45222, 15)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file, header=0)\n",
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['<=50K', '>50K'], dtype=object), array([34014, 11208]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['class'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class']=df['class'].map({'<=50K': 0, '>50K': 1}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age :  5\n",
      "workclass :  7\n",
      "fnlwgt :  26741\n",
      "education :  16\n",
      "education-num :  16\n",
      "marital-status :  7\n",
      "occupation :  14\n",
      "relationship :  6\n",
      "race :  5\n",
      "sex :  2\n",
      "capitalgain :  5\n",
      "capitalloss :  5\n",
      "hoursperweek :  5\n",
      "native-country :  41\n",
      "class :  2\n"
     ]
    }
   ],
   "source": [
    "for c in df.columns:\n",
    "    print(c, ': ', len(df[c].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete redundant and noisy features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df[\"relationship\"]\n",
    "del df['fnlwgt']\n",
    "del df['education-num']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  ['State-gov' 'Self-emp-not-inc' 'Private' 'Federal-gov' 'Local-gov'\n",
      " 'Self-emp-inc' 'Without-pay']\n",
      "After:  ['Gov' 'Self-emp' 'Private' 'Without-pay']\n"
     ]
    }
   ],
   "source": [
    "print('Before: ', df.workclass.unique())\n",
    "df.workclass = df.workclass.replace({'Self-emp-not-inc': 'Self-emp',\n",
    "                                    'Self-emp-inc': 'Self-emp',\n",
    "                                    'Local-gov': 'Gov',\n",
    "                                    'Federal-gov': 'Gov',\n",
    "                                    'State-gov': 'Gov'})\n",
    "print('After: ', df.workclass.unique())\n",
    "le = LabelEncoder()\n",
    "df['workclass'] = le.fit_transform(df['workclass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  ['Bachelors' 'HS-grad' '11th' 'Masters' '9th' 'Some-college' 'Assoc-acdm'\n",
      " '7th-8th' 'Doctorate' 'Assoc-voc' 'Prof-school' '5th-6th' '10th'\n",
      " 'Preschool' '12th' '1st-4th']\n",
      "After:  ['Bachelors' 'HS-grad' 'No-school' 'Masters' 'College' 'Doctorate'\n",
      " 'Prof-school']\n"
     ]
    }
   ],
   "source": [
    "print('Before: ', df.education.unique())\n",
    "df.education = df.education.replace({'Preschool': 'No-school',\n",
    "                                        '1st-4th': 'No-school',\n",
    "                                        '5th-6th': 'No-school',\n",
    "                                        '7th-8th': 'No-school',\n",
    "                                        '9th': 'No-school',\n",
    "                                        '10th': 'No-school',\n",
    "                                        '11th': 'No-school',\n",
    "                                        '12th': 'No-school',\n",
    "                                        'Some-college': 'College',\n",
    "                                        'Assoc-voc': 'College',\n",
    "                                        'Assoc-acdm': 'College'})\n",
    "print('After: ', df.education.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  ['Never-married' 'Married-civ-spouse' 'Divorced' 'Married-spouse-absent'\n",
      " 'Separated' 'Married-AF-spouse' 'Widowed']\n",
      "After:  ['Not-married' 'Married' 'Separated' 'Widowed']\n"
     ]
    }
   ],
   "source": [
    "print('Before: ', df['marital-status'].unique())\n",
    "df['marital-status'].replace(['Married-civ-spouse'], 'Married', inplace=True)\n",
    "df['marital-status'].replace('Never-married', 'Not-married', inplace=True)\n",
    "df['marital-status'].replace(['Divorced'], 'Separated', inplace=True)\n",
    "df['marital-status'].replace(['Separated'], 'Separated', inplace=True)\n",
    "df['marital-status'].replace(['Married-spouse-absent'], 'Not-married', inplace=True)\n",
    "df['marital-status'].replace(['Married-AF-spouse'], 'Married', inplace=True)\n",
    "print('After: ', df['marital-status'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  ['United-States' 'Cuba' 'Jamaica' 'India' 'Mexico' 'Puerto-Rico'\n",
      " 'Honduras' 'England' 'Canada' 'Germany' 'Iran' 'Philippines' 'Poland'\n",
      " 'Columbia' 'Cambodia' 'Thailand' 'Ecuador' 'Laos' 'Taiwan' 'Haiti'\n",
      " 'Portugal' 'Dominican-Republic' 'El-Salvador' 'France' 'Guatemala'\n",
      " 'Italy' 'China' 'South' 'Japan' 'Yugoslavia' 'Peru'\n",
      " 'Outlying-US(Guam-USVI-etc)' 'Scotland' 'Trinadad&Tobago' 'Greece'\n",
      " 'Nicaragua' 'Vietnam' 'Hong' 'Ireland' 'Hungary' 'Holand-Netherlands']\n",
      "After:  ['N-America' 'MS-America' 'Asia' 'Europe' 'South']\n"
     ]
    }
   ],
   "source": [
    "print('Before: ', df['native-country'].unique())\n",
    "df['native-country'].replace(['United-States'], 'N-America', inplace=True)\n",
    "df['native-country'].replace(['Mexico'], 'N-America', inplace=True)\n",
    "df['native-country'].replace(['Philippines'], 'Asia', inplace=True)\n",
    "df['native-country'].replace(['Germany'], 'Europe', inplace=True)\n",
    "df['native-country'].replace(['Puerto-Rico'], 'N-America', inplace=True)\n",
    "df['native-country'].replace(['Canada'], 'N-America', inplace=True)\n",
    "df['native-country'].replace(['India'], 'Asia', inplace=True)\n",
    "df['native-country'].replace(['El-Salvador'], 'MS-America', inplace=True)\n",
    "df['native-country'].replace(['Cuba'], 'MS-America', inplace=True)\n",
    "df['native-country'].replace(['England'], 'Europe', inplace=True)\n",
    "df['native-country'].replace(['Jamaica'], 'MS-America', inplace=True)\n",
    "df['native-country'].replace(['Italy'], 'Europe', inplace=True)\n",
    "\n",
    "df['native-country'].replace(['China'], 'Asia', inplace=True)\n",
    "df['native-country'].replace(['Dominican-Republic'], 'MS-America', inplace=True)\n",
    "df['native-country'].replace(['Vietnam'], 'Asia', inplace=True)\n",
    "df['native-country'].replace(['Guatemala'], 'MS-America', inplace=True)\n",
    "df['native-country'].replace(['Japan'], 'Asia', inplace=True)\n",
    "df['native-country'].replace(['Columbia'], 'MS-America', inplace=True)\n",
    "df['native-country'].replace(['Poland'], 'Europe', inplace=True)\n",
    "df['native-country'].replace(['Taiwan'], 'Asia', inplace=True)\n",
    "df['native-country'].replace(['Haiti'], 'MS-America', inplace=True)\n",
    "df['native-country'].replace(['Iran'], 'Asia', inplace=True)\n",
    "df['native-country'].replace(['Portugal'], 'Europe', inplace=True)\n",
    "df['native-country'].replace(['Nicaragua'], 'MS-America', inplace=True)\n",
    "\n",
    "df['native-country'].replace(['Peru'], 'MS-America', inplace=True)\n",
    "df['native-country'].replace(['Greece'], 'Europe', inplace=True)\n",
    "df['native-country'].replace(['Ecuador'], 'MS-America', inplace=True)\n",
    "df['native-country'].replace(['France'], 'Europe', inplace=True)\n",
    "df['native-country'].replace(['Ireland'], 'Europe', inplace=True)\n",
    "df['native-country'].replace(['Hong'], 'Asia', inplace=True)\n",
    "df['native-country'].replace(['Trinadad&Tobago'], 'MS-America', inplace=True)\n",
    "df['native-country'].replace(['Cambodia'], 'Asia', inplace=True)\n",
    "df['native-country'].replace(['Laos'], 'Asia', inplace=True)\n",
    "df['native-country'].replace(['Thailand'], 'Asia', inplace=True)\n",
    "df['native-country'].replace(['Yugoslavia'], 'Europe', inplace=True)\n",
    "df['native-country'].replace(['Outlying-US(Guam-USVI-etc)'], 'N-America', inplace=True)\n",
    "\n",
    "df['native-country'].replace(['Hungary'], 'Europe', inplace=True)\n",
    "df['native-country'].replace(['Honduras'], 'MS-America', inplace=True)\n",
    "df['native-country'].replace(['Scotland'], 'Europe', inplace=True)\n",
    "df['native-country'].replace(['Holand-Netherlands'], 'Europe', inplace=True)\n",
    "print('After: ', df['native-country'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c in df.columns:\n",
    "#     print(f'{c}: {df[c].unique()}')\n",
    "#     print(df[c].value_counts())\n",
    "#     print('------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols = set(df.select_dtypes(['object']).columns)\n",
    "df_obj = df[obj_cols]\n",
    "df_obj = pd.get_dummies(df_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(obj_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(df_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = set(df.columns)-{'workclass', 'class'}\n",
    "df_x = df[x_col]\n",
    "y_class = df['class'].values\n",
    "y_workclass = df['workclass'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Label correlation to make prediction of attribute 'class' secure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34014 11208\n"
     ]
    }
   ],
   "source": [
    "scale = 0\n",
    "c0, c1 = df['class'].value_counts()\n",
    "print(c0, c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(df, eps=1, del_f=2):\n",
    "    df_secure = df.copy()\n",
    "    for i in df_secure.index:\n",
    "        noise = np.random.laplace(scale=del_f/eps, size=df_secure.shape[1])\n",
    "        df_secure.loc[i] += noise\n",
    "    return df_secure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(df, num_class, mode='', eps=None):\n",
    "    if eps and eps!='NA':\n",
    "        df = add_noise(df, eps=eps)\n",
    "    X = torch.Tensor(df.values)\n",
    "    Y = torch.Tensor(y_class if num_class==2 else y_workclass)\n",
    "    scores = []\n",
    "    for clf in tqdm.tqdm(classifiers, desc='\\tClassifier'):\n",
    "        if num_class==2:\n",
    "            sc = Prf1a()\n",
    "        else:\n",
    "             sc = ConfusionMatrix(num_class)\n",
    "        name = clf.__class__.__name__\n",
    "        for sp in kf.split(X):\n",
    "            x_train, y_train = X[sp[0]], Y[sp[0]]\n",
    "            x_test, y_test = X[sp[1]], Y[sp[1]]\n",
    "            _sc = classify(clf, x_train, y_train, x_test, y_test, num_class)\n",
    "            sc.accumulate(_sc)\n",
    "        scores.append([eps, mode, name] + [round(i, 4) for i in sc.prfa()])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Noise amount:   0%|          | 0/11 [00:00<?, ?it/s]\n",
      "\tClassifier:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\tClassifier:  33%|███▎      | 1/3 [00:01<00:02,  1.23s/it]\u001b[A\n",
      "\tClassifier:  67%|██████▋   | 2/3 [00:08<00:02,  3.00s/it]\u001b[A\n",
      "\tClassifier: 100%|██████████| 3/3 [00:17<00:00,  5.93s/it]\u001b[A\n",
      "\n",
      "\tClassifier:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\tClassifier:  33%|███▎      | 1/3 [00:01<00:02,  1.26s/it]\u001b[A\n",
      "\tClassifier:  67%|██████▋   | 2/3 [00:11<00:03,  3.94s/it]\u001b[A\n",
      "\tClassifier: 100%|██████████| 3/3 [00:21<00:00,  7.20s/it]\u001b[A\n",
      "Noise amount:   9%|▉         | 1/11 [00:39<06:33, 39.39s/it]\n",
      "\tClassifier:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\tClassifier:  33%|███▎      | 1/3 [00:39<01:19, 39.65s/it]\u001b[A\n",
      "\tClassifier:  67%|██████▋   | 2/3 [03:05<01:11, 71.58s/it]\u001b[A\n",
      "\tClassifier: 100%|██████████| 3/3 [04:38<00:00, 92.73s/it]\u001b[A\n",
      "\n",
      "\tClassifier:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\tClassifier:  33%|███▎      | 1/3 [00:52<01:44, 52.22s/it]\u001b[A\n",
      "\tClassifier:  67%|██████▋   | 2/3 [03:53<01:30, 90.99s/it]\u001b[A\n",
      "\tClassifier: 100%|██████████| 3/3 [05:29<00:00, 109.88s/it][A\n",
      "Noise amount:  18%|█▊        | 2/11 [11:14<32:43, 218.12s/it]\n",
      "\tClassifier:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\tClassifier:  33%|███▎      | 1/3 [00:25<00:51, 25.98s/it]\u001b[A\n",
      "\tClassifier:  67%|██████▋   | 2/3 [02:09<00:49, 49.34s/it]\u001b[A\n",
      "\tClassifier: 100%|██████████| 3/3 [03:42<00:00, 74.21s/it]\u001b[A\n",
      "\n",
      "\tClassifier:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\tClassifier:  33%|███▎      | 1/3 [00:38<01:17, 38.85s/it]\u001b[A\n",
      "\tClassifier:  67%|██████▋   | 2/3 [02:58<01:09, 69.15s/it]\u001b[A\n",
      "\tClassifier: 100%|██████████| 3/3 [04:33<00:00, 91.04s/it]\u001b[A\n",
      "Noise amount:  27%|██▋       | 3/11 [19:58<41:18, 309.78s/it]\n",
      "\tClassifier:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\tClassifier:  33%|███▎      | 1/3 [00:24<00:48, 24.41s/it]\u001b[A\n",
      "\tClassifier:  67%|██████▋   | 2/3 [01:57<00:45, 45.11s/it]\u001b[A\n",
      "\tClassifier: 100%|██████████| 3/3 [03:30<00:00, 70.14s/it]\u001b[A\n",
      "\n",
      "\tClassifier:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\tClassifier:  33%|███▎      | 1/3 [00:33<01:06, 33.00s/it]\u001b[A\n",
      "\tClassifier:  67%|██████▋   | 2/3 [03:30<01:16, 76.47s/it]\u001b[A\n",
      "\tClassifier: 100%|██████████| 3/3 [05:25<00:00, 108.62s/it][A\n",
      "Noise amount:  36%|███▋      | 4/11 [29:21<45:01, 385.92s/it]\n",
      "\tClassifier:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\tClassifier:  33%|███▎      | 1/3 [00:30<01:01, 30.78s/it]\u001b[A\n",
      "\tClassifier:  67%|██████▋   | 2/3 [02:11<00:51, 51.66s/it]\u001b[A\n",
      "\tClassifier: 100%|██████████| 3/3 [03:58<00:00, 79.49s/it]\u001b[A\n",
      "\n",
      "\tClassifier:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\tClassifier:  33%|███▎      | 1/3 [00:33<01:06, 33.30s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for eps in tqdm.tqdm(['NA'] + np.arange(0.1, 5, 0.5).tolist(), desc='Noise amount'):\n",
    "    for attr in ['class', 'workclass']:\n",
    "        num_cls = 2 if attr=='class' else 7\n",
    "        scores += run(df_x, num_cls, attr, eps=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('noisy_scores.dat', 'wb') as fp:\n",
    "    pickle.dump(itemlist, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base scores on classifying attribute 'class'\n",
    "- KNeighborsClassifier [0.6565, 0.5988, 0.6263, 0.8229]\n",
    "- DecisionTreeClassifier [0.6994, 0.588, 0.6389, 0.8352]\n",
    "- RandomForestClassifier [0.7061, 0.6085, 0.6537, 0.8402]\n",
    "- AdaBoostClassifier [0.7399, 0.6057, 0.6661, 0.8495]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base scores on classifying attribute 'workclass'\n",
    "- KNeighborsClassifier [0.2038, 0.2221, 0.2125, 0.704]\n",
    "- DecisionTreeClassifier [0.2041, 0.2358, 0.2188, 0.7242]\n",
    "- RandomForestClassifier [0.2041, 0.251, 0.2251, 0.7429]\n",
    "- AdaBoostClassifier [0.1858, 0.2619, 0.2174, 0.7481]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secure_x Score on classifying attribute 'class'\n",
    "- KNeighborsClassifier [0.2394, 0.1456, 0.1811, 0.6736]\n",
    "- DecisionTreeClassifier [0.2454, 0.0865, 0.1279, 0.7076]\n",
    "- RandomForestClassifier [0.2487, 0.0662, 0.1046, 0.719]\n",
    "- AdaBoostClassifier [0.0, 0.0, 0.0, 0.7522]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secure_x Score on classifying attribute 'workclass'\n",
    "- KNeighborsClassifier [0.1429, 0.1437, 0.1433, 0.6375]\n",
    "- DecisionTreeClassifier [0.1425, 0.1417, 0.1421, 0.6675]\n",
    "- RandomForestClassifier [0.1416, 0.1371, 0.1393, 0.7015]\n",
    "- AdaBoostClassifier [0.1428, 0.1052, 0.1212, 0.7364]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StratifiedKFold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
